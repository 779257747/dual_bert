{
    "output_dir": "/home/yaoxingzhi1/JD_Young/bert-knn-model-list/knn_model_list/dual_bert",
    "warm_up_model": "",
    "query_model_config": 
    {
        "attention_probs_dropout_prob": 0.1,
        "directionality": "bidi",
        "hidden_act": "gelu",
        "hidden_dropout_prob": 0.1,
        "hidden_size": 768,
        "initializer_range": 0.02,
        "intermediate_size": 3072,
        "layer_norm_eps": 1e-12,
        "max_position_embeddings": 512,
        "model_type": "bert",
        "num_attention_heads": 12,
        "num_hidden_layers": 6,
        "pad_token_id": 0,
        "pooler_fc_size": 768,
        "pooler_num_attention_heads": 12,
        "pooler_num_fc_layers": 6,
        "pooler_size_per_head": 128,
        "pooler_type": "first_token_transform",
        "type_vocab_size": 2,
        "vocab_size": 21128,
        "term_vocab_size": 542099,
        "num_labels": 110910,
        "problem_type": "multi_label_classification"
    },
    "doc_model_config": {
        "attention_probs_dropout_prob": 0.1,
        "directionality": "bidi",
        "hidden_act": "gelu",
        "hidden_dropout_prob": 0.1,
        "hidden_size": 768,
        "initializer_range": 0.02,
        "intermediate_size": 3072,
        "layer_norm_eps": 1e-12,
        "max_position_embeddings": 512,
        "model_type": "bert",
        "num_attention_heads": 12,
        "num_hidden_layers": 6,
        "pad_token_id": 0,
        "pooler_fc_size": 768,
        "pooler_num_attention_heads": 12,
        "pooler_num_fc_layers": 6,
        "pooler_size_per_head": 128,
        "pooler_type": "first_token_transform",
        "type_vocab_size": 2,
        "vocab_size": 21128,
        "term_vocab_size": 542099,
        "num_labels": 110910,
        "problem_type": "multi_label_classification"
    },
    "train_file": "/home/yaoxingzhi1/knn/dataset/train_format.jsonl",
    "eval_file": "",
    "num_train_epochs": 5,
    "total_train_batch_size": 64,
    "gradient_accumulation_steps": 2,
    "learning_rate": 5e-5,
    "warmup_steps": 0,
    "max_seq_length": 512,
    "logging_steps": 100,
    "save_steps": 10000,
    "save_total_limit": 3,
    "lr_scheduler_type": "cosine",
    "gradient_checkpointing": false,
    "disable_tqdm": false,
    "optim": "adamw_hf",
    "seed": 42,
    "fp16": true,
    "report_to": "tensorboard",
    "dataloader_num_workers": 5,
    "save_strategy": "steps",
    "weight_decay": 0,
    "max_grad_norm": 1.0,
    "remove_unused_columns": false,

    "sample_num": 426221,

    "FeatureConfig": [
        {
            "name": "query",
            "tokenizer_name": "bert_tokenizer",
            "vocab_path": "",
            "tokenize_type": "str2intlist",
            "collate_type": "pad",
            "dtype": "int",
            "is_pretrain": false
        },
        {
            "name": "positive",
            "tokenizer_name": "bert_tokenizer",
            "vocab_path": "",
            "tokenize_type": "str2intlist",
            "collate_type": "pad",
            "dtype": "int",
            "is_pretrain": false
        },
        {
            "name": "negative",
            "tokenizer_name": "bert_tokenizer",
            "vocab_path": "",
            "tokenize_type": "str2intlist",
            "collate_type": "pad",
            "dtype": "int",
            "is_pretrain": false
        }
    ]
}
